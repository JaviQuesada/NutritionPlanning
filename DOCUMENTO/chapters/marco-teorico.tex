\chapter{Marco teórico}
\label{ch:marco-teorico}

En 1975 John Holland propone imitar los procesos biológicos naturales que rigen la selección natural usando ordenadores, lo que sería el principio de los algoritmos genéticos (AGs)~\cite{holland1975}. En un AG, las soluciones son modeladas como individuos o cromosomas, que generalmente se representan como cadenas de bits, aunque también se puede usar otro tipo de cadenas. Estas soluciones son evaluadas por una función de aptitud o fitness, y las más adecuadas son seleccionadas para reproducirse mediante cruzamiento y mutación, procesos que mezclan y alteran aleatoriamente los cromosomas para generar diversidad. Los descendientes resultantes forman nuevas generaciones que vuelven a ser evaluadas, creando un ciclo que se repite hasta cumplir alguna condición de parada, como pudiera ser un número limitado de generaciones o que se alcance la solución deseada.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/algoritmo-genetico.png}
    \caption{Algoritmo genético simple.}
    \label{fig:algoritmo-genetico}
  \end{figure}

Explicado el concepto general, se va a desglosar cada una de las fases de la figura \ref{fig:algoritmo-genetico}, que muestra el esquema básico de un algoritmo genético.

\section{Población}

Antes de explicar la generación de una población inicial, es necesario conocer algunos conceptos que son usados para representar y entender las soluciones. Son términos utilizados en la biología y en el campo de la genética. 

\begin{itemize}
    \item \textbf{Gen.} Es la unidad básica de información en un cromosoma. En una cadena de bits que representa una solución, cada bit puede considerarse un gen. En el caso que se trata en este PFG, el menú semanal, cada tipo de comida se podría considerar un gen. Por ejemplo, un gen sería bebida, plato principal o postre.
    \item \textbf{Alelo.} Es la forma específica o valor que puede tomar un gen. Siguiendo el ejemplo de bebida, posibles alelos serían agua, té o cerveza.
    \item \textbf{Cromosoma.} Es una colección de genes y representa una solución completa al problema de optimización. El cromosoma es la cadena de bits completa. En nuestro caso, la lista completa de alimentos seleccionados para una semana es el cromosoma. 
    \item \textbf{Fenotipo.} Es la manifestación real de la solución codificada. En el PFG sería cómo se preparan y sirven estos alimentos en la realidad.
\end{itemize}

En la figura \ref{fig:cromosoma} se expone la estructura de un cromosoma con el ejemplo del menú semanal de comida.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.625\textwidth]{figures/cromosoma.png}
  \caption{Estructura de un cromosoma.}
  \label{fig:cromosoma}
\end{figure}
\newpage
La generación de una población inicial implica crear un conjunto de soluciones candidatas. Generalmente, los individuos son seleccionados aleatoriamente dentro de los límites definidos en cada problema, asegurando que todas las áreas del espacio de búsqueda puedan ser exploradas. También existen métodos alternativos de generación que aplican ciertas restricciones para formar soluciones iniciales más prometedoras. Tomando de ejemplo el menú semanal, el espacio de búsqueda comprendería la base de datos en la que aparecen todos los alimentos con sus respectivas calorías y macronutrientes. 

\section{Evaluación}
\label{ch:evaluacion}

Se mide lo bueno que es un individuo para nuestros propósitos (la calidad del individuo). Lo más importante es definir una función de fitness correcta y representativa del problema a evaluar. Si se trata de un problema multiobjetivo, se tendrá que diseñar una función de fitness diferente por cada objetivo.

Según vayan pasando generaciones, la población inicial irá evolucionando hacia poblaciones candidatas que presentarán una mejor aptitud. Si la población ha alcanzado el objetivo, la condición de parada se activará, convirtiendo el conjunto de individuos candidatos en la población óptima. En caso de no alcanzarlo, seguirá evolucionando hacia otra población candidata distinta.

Para diseñar una función de fitness acorde al problema y al objetivo (u objetivos) se pueden seguir los siguientes pasos:

\begin{enumerate}
  \item Determinar si el objetivo es maximizar o minimizar un valor específico. En el caso que se trata en este proyecto, se busca que la diferencia entre las calorías necesarias y la suma de las calorías de los alimentos sea la menor posible, por lo que se trataría de un problema de minimización.
  \item Identificar las restricciones. En el ejemplo de los alimentos, una podría ser los límites superior e inferior de calorías permitidas.
  \item Definir la función matemática que represente el objetivo del problema. Si existen múltiples objetivos, se pueden ponderar.
  \item Incorporar las penalizaciones para soluciones que no cumplan con las restricciones.
\end{enumerate}

Por lo tanto, la mejor solución debería recibir la mejor evaluación. Esto ayudará al algoritmo a entender el camino a seguir, ya que penalizará las soluciones no factibles.

\subsection{Restricciones}
\label{ch:restricciones}

Uno de los apartados a destacar cuando se diseña la función de calidad es entender cómo se manejan las restricciones para asegurar que las soluciones generadas sean viables y de alta calidad.

Existen tres tipos de restricciones que limitan el espacio de soluciones válidas. Sea \textit{x} las variables del problema:

\begin{itemize}
  \item Restricciones de igualdad. $h_j(x) = 0$
  \item Restricciones de desigualdad. $g_k(x) \geq 0$ ó $g_k(x) \leq 0$
  \item Restricciones de contorno o de caja (\textit{box-constraints}). $x^L \leq x \leq x^U$
\end{itemize}

Estos tipos de restricciones se pueden tratar mediante distintos métodos, que también son probados de manera práctica en el apartado \ref{ch:manejo-restricciones}. En el trabajo de Carlos A. Coello (2022)~\cite{coello2022} se hace un recopilatorio de algunos de los métodos más usados y sus consiguientes ventajas y desventajas. Los más importantes son:

\begin{itemize}
  \item \textbf{Funciones de penalización.} Se penalizan las soluciones no factibles. Estas penalizaciones representan cómo de lejos está la solución de la región factible. Se transforma un problema con restricciones en uno sin restricciones utilizando una función objetivo de penalización:
  
  \[
  F(x) = f(x) + \sum_{j=1}^{m} R_j \cdot p_j(x)^\beta
  \]
  
  \begin{itemize}
    \item \( f(x) \) es la función objetivo original que se desea optimizar.
    \item \( R_j \) es un parámetro de penalización definido por el usuario para la restricción \( c_j(x) \), cuya función de penalización es \( p_j(x) \)
    \item \( \beta \) (comúnmente 1 o 2) es una constante definida por el usuario que determina cómo se pondera la violación de la restricción en la función de penalización.
    \item En problemas de maximización la suma se convierte en negativa.     
  \end{itemize}

  \newpage
  Existen varios métodos de penalización:
  
    \begin{itemize}
      \item \textbf{Penalización estática.} Se usa un valor fijo \( R_j \). Se puede ver su implementación en el problema del PFG en el punto \ref{ch:penalizacion-estatica}.
      \item \textbf{Penalización dinámica.} Se usa un factor \( R = (C \cdot t) ^ {\alpha} \), donde \( C \) y \( \alpha \) son constantes y \( t \) es el número de iteración.
      \item \textbf{Penalización adaptativa.} La penalización se adapta en función de la factibilidad de las soluciones.
    \end{itemize}
  \item \textbf{Separatista.} Dividen el problema en subproblemas más manejables que se pueden resolver por separado y luego combinar. Las restricciones y los objetivos se tratan de forma separada. Un método separatista se trata en el punto \ref{ch:metodo-separatista}.
  \begin{comment}
  \item \textbf{Preservación de la factibilidad.} Se usan representaciones especiales (codificación binaria, entera, real, etc.) que simplifican la forma del espacio de búsqueda y operadores que mantienen la factibilidad de las soluciones, lo que elimina las soluciones inválidas en cada etapa del algoritmo.
  \end{comment}
  \item \textbf{Reparación.} Se modifican las soluciones candidatas inviables de forma que no violen las restricciones.
\end{itemize}

\subsection{Condición de parada}

Tras la evaluación de calidad la condición de parada determina cuándo el algoritmo debe detenerse y presentar la solución. Si bien existe una gran variedad de condiciones de parada, las más comunes son:

\begin{itemize}
  \item Aptitud del individuo. El algoritmo se detiene si se alcanza una solución, ya sea alcanzando el valor objetivo o estando dentro de unos umbrales predefinidos.
  \item Número máximo de generaciones. El algoritmo se detiene si la población ha evolucionado un número de veces predefinido.
  \item Tiempo máximo de ejecución. Se detiene si el tiempo de ejecución es demasiado elevado.
  \item Convergencia. La ejecución puede detenerse si la población muestra poca o ninguna mejora en la aptitud durante un número determinado de generaciones consecutivas.
\end{itemize}
\newpage
\section{Operadores}

Son los procesos que se aplican a poblaciones de individuos para desarrollar generaciones futuras. Sirven para la exploración del espacio de soluciones y para la mejora de las poblaciones a través de las generaciones. Se busca que el conjunto de individuos presente una alta diversidad, ya que si es baja se corre el riesgo de caer en mínimos locales, lo que no permitiría explorar el espacio de soluciones ampliamente. En la figura \ref{fig:operadores} aparecen los operadores básicos en los algoritmos evolutivos, que son los que se van a explicar en más detalle.

\begin{figure}[H]
  \centering
  \includegraphics[width=1\textwidth]{figures/operadores.png}
  \caption{Operadores.}
  \label{fig:operadores}
\end{figure}

\subsection{Selección}
\label{Seleccion}

El primero de los operadores básicos. Elige un individuo para reproducirlo. Comúnmente, se busca un equilibrio entre la diversidad y la convergencia. El algoritmo debe explorar el espacio de búsqueda en amplitud, ya que podría caer en mínimos locales si la población es muy parecida entre sí, lo que no permitiría encontrar buenas soluciones. Pero también es de interés que las poblaciones candidatas vayan evolucionando hacia una mayor aptitud, reconduciendo el algoritmo por zonas del espacio de búsqueda más probables de encontrar una solución.

Si bien se puede seleccionar de manera equiprobable, existen métodos basados en la aptitud del individuo que buscan respetar este equilibrio. Estos son algunos:

\begin{itemize}
  \item \textbf{Método estándar (rueda de la fortuna).} Asigna a cada individuo una probabilidad proporcional a su fitness, por lo que los más aptos tienen mayor probabilidad de reproducirse. Existe un derivado de este método en el que se normalizan las probabilidades, lo que favorece aún más a los de mayor calidad.\newpage
  \item \textbf{Método del rango.} Se ordenan los individuos según su aptitud, y la probabilidad de selección se asigna según este ránking.
  \item \textbf{Selección por torneo.} Se escoge aleatoriamente un subconjunto de individuos de la población, y el mejor de este es elegido. Este es el método de selección usado en el desarrollo del algoritmo nutricional (sección \ref{ch:explicacion-algoritmo}).
\end{itemize}

\subsubsection{Selección ambiental (Reemplazo)}

Aparte de los métodos basados en la aptitud, se puede usar usa la técnica de la selección ambiental para seleccionar aquellos individuos que puedan influir significativamente en la eficacia del algoritmo genético. Existen varios métodos de selección ambiental:

\begin{itemize}
  \item \textbf{Reemplazo generacional completo.} Método tradicional en la selección y explicado en el apartado \ref{Seleccion}. Toda la población actual es reemplazada por una nueva. Promueve altas tasas de diversidad, pero conlleva una aptitud de los individuos irregular.
  \item \textbf{Reemplazo generacional parcial (\textit{Steady-State}).} Solo una parte de la población es reemplazada en cada generación. Se promueve una mejora constante en la calidad ya que las soluciones con un fitness elevado pueden mantenerse.
  \item \textbf{Reemplazo elitista.} Escoge los mejores individuos de una generación para que se mantengan en la siguiente. Esto ayuda a que la calidad del mejor individuo de una generación sea siempre igual o superior a su equivalente de la generación anterior, consiguiendo una progresión constante hacia la solución óptima, es decir, una mayor convergencia.
  \item \textbf{Selección $(\mu,\lambda)$.} De $\mu$ padres se generan $\lambda$ hijos. Los $\mu$ mejores de los $\lambda$ hijos forman la siguiente generación de padres. Es decir, si se tiene 50 padres $(\mu)$ y se generan 100 descendientes $(\lambda)$, se seleccionan los 50 mejores de los 100 descendientes para la siguiente generación.
  \item \textbf{Selección $(\mu+\lambda)$.} Igual que en la anterior, de $\mu$ padres se generan $\lambda$ hijos, pero en este caso los $\mu$ mejores de la combinación entre los $\mu$ padres y los $\lambda$ hijos forman la siguiente generación. En este caso, con el mismo ejemplo de los 50 padres y los 100 descendientes, se seleccionan los 50 de los 150 individuos combinados para la siguiente generación.
\end{itemize}

\subsection{Cruce}

Se combina el material genético de dos individuos, padres, para producir descendencia, hijos. Es decir, se utiliza para intercambiar características de dos soluciones parentales, con el objetivo de generar nuevas soluciones. Se aplica con probabilidad \(P_c\) . Al promover la mezcla de genes, ayuda a aumentar la diversidad y la convergencia, gracias a la generación de nuevos descendientes con características deseables. Se usan distintos métodos:

\begin{itemize}
  \item \textbf{Cruce de un punto.} Como se muestra en la figura \ref{fig:cruce}, se selecciona aleatoriamente una posición en el cromosoma. Todos los genes que están antes de este punto se intercambian con los que están después en la otra cadena, y viceversa, para producir dos nuevos descendientes.
  
  \begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/cruce.png}
    \caption{Cruce de un punto.}
    \label{fig:cruce}
  \end{figure}

  \item \textbf{Cruce de dos puntos.} Similar al cruce de un punto, pero se seleccionan dos puntos de corte. Las cadenas de genes entre estos dos puntos se intercambian entre los dos padres.
  \item \textbf{Cruce uniforme.} Cada gen tiene una probabilidad igual de ser elegido de uno de los dos padres.
\end{itemize}
\newpage
\subsection{Mutación}

Último de los operadores básicos. Se recorre toda la cadena, mutando cada gen con probabilidad \(P_m\) , es decir, eligiendo un nuevo valor mediante una elección equiprobable dentro del alfabeto. La mutación aumenta la diversidad y ayuda a no caer en mínimos locales. Algunos de los métodos usados son:

\begin{itemize}
  \item \textbf{Mutación uniforme.} Cada gen puede cambiar a otro valor con probabilidad \(P_m\), como se expone en la figura \ref{fig:mutación}.

  \begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/mutacion.png}
    \caption{Mutación uniforme.}
    \label{fig:mutación}
  \end{figure}

  \item \textbf{Mutación por intercambio.} Dos genes aleatorios en el cromosoma son seleccionados y sus posiciones se intercambian. 
\end{itemize}

\section{Tipos de algoritmo}

Si bien existen casos en los que solo es necesaria la optimización de un objetivo, existe una gran diversidad de problemas en la que pueden aparecer varios que se deben maximizar o minimizar. Debido a esto, existe una clasificación de los problemas según el número de objetivos a optimizar. Destacan dos grandes grupos: los problemas de optimización con un solo objetivo o \textit{Single-objective Optimization Problem (SOP)}, y los problemas de optimización multiobjetivo o \textit{Multi-objective Optimization Problem (MOP)}.

\subsection{Single-objective Optimization Problem (SOP)}

Los algoritmos que resuelven problemas \textit{SOP} se enfocan en optimizar una única función objetivo. La meta es encontrar la mejor solución posible según se busque maximizar o minimizar la función. Se usan algoritmos mono-objetivo cuando existe un único criterio de éxito.

Los algoritmos mono-objetivo presentan una función objetivo que asigna un valor numérico a cada solución, indicando su calidad. Cada solución está representada por un vector de variables de decisión, que son los parámetros que se pueden ajustar dentro del espacio de decisión. Estas soluciones deben pertenecer al conjunto factible, que incluye aquellas que cumplen con todas las restricciones del problema.

El algoritmo más usado para los problemas mono-objetivo es el \textit{''Genetic Algorithm'' (GA)}, cuyo funcionamiento sigue los pasos explicados a lo largo del capítulo \ref{ch:marco-teorico}. Destaca por su simplicidad y su capacidad para explorar grandes espacios de búsqueda.

\subsection{Multi-objective Optimization Problem (MOP)}

Los algoritmos multi-objetivo buscan optimizar múltiples funciones simultáneamente. La meta es encontrar un conjunto de soluciones que represente un equilibrio entre los distintos criterios de éxito, conocido como conjunto de Pareto.

Una solución se considera no dominada si no existe otra que mejore en, al menos, uno de los objetivos sin empeorar en los demás. El conjunto de todas las soluciones no dominadas se conoce como el conjunto de Pareto, como se ha mencionado antes.

Al igual que en los mono-objetivo, cada solución está representada por un vector de variables de decisión. Estas soluciones deben pertenecer también al conjunto factible. La diferencia se encuentra en la existencia de múltiples funciones objetivo que asignan valores numéricos a cada solución, indicando su calidad en diferentes dimensiones según el número de objetivos.

Algunos de los algoritmos más usados para los \textit{MOP} son el \textit{''Non-dominated Sorting Genetic Algorithm II'' (NSGA-II)}, el \textit{''Strength Pareto Evolutionary Algorithm 2'' (SPEA2)} o el \textit{''Multi-Objective Evolutionary Algorithm based on Decomposition'' (MOEA/D)}. Usan criterios basados en Pareto para evaluar, clasificar y seleccionar las soluciones. Buscan dispersar las soluciones para aumentar la diversidad y explorar el espacio de soluciones. Aun así, presentan grandes diferencias a la hora de desarrollar el algoritmo evolutivo.

\subsubsection{Non-dominated Sorting Genetic Algorithm II (NSGA-II)}
\label{ch:nsga2}

Este algoritmo sigue el funcionamiento general de un algoritmo genético, pero presenta ciertas modificaciones para los algoritmos multi-objetivo, como se muestra en la figura \ref{fig:nsga2}. Tras realizar la evaluación, las soluciones se ordenan en diferentes frentes de Pareto. En el primer frente se encuentran las soluciones no dominadas, en el segundo las soluciones dominadas solo por soluciones del primer frente, y así sucesivamente. Tras esto, se calcula el \textit{''crowd distance''}, una medida usada para preservar la diversidad de las soluciones. Se evalúa cómo de cerca están las soluciones entre sí en el mismo frente. Cuanto mayor sea la distancia, más aislada y diversa es la solución, lo que ayuda a explorar en profundidad el espacio de soluciones.

\textit{NSGA-II} usa elitismo, ya que combina la población de los padres y los descendientes y escoge a los mejores individuos para la siguiente generación basados en la clasificación de Pareto y en el \textit{''crowding distance''}. Además, se hace uso de la selección por torneo para elegir a los padres que se usarán en la reproducción, también usando de referencia las medidas antes citadas.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{figures/nsga2.png}
  \caption{Estructura general del algoritmo NSGA-II. Fuente \cite{nsga2_imagen}}
  \label{fig:nsga2}
\end{figure}

\subsubsection{Strength Pareto Evolutionary Algorithm 2 (SPEA2)}
\label{ch:spea2}

El \textit{SPEA2} también está optimizado para problemas multi-objetivo y, al igual que el NSGA-II, tiene modificaciones respecto al funcionamiento básico del algoritmo genético.

En la evaluación, a cada solución se le asigna una fuerza que refleja el número de soluciones que domina, como se expone en la figura \ref{fig:spea2}. Tras esto, se usa una medida de densidad para evaluar cuán poblada está la área alrededor de cada solución. El fitness se calcula sumando la fuerza y esta medida de densidad, lo que ayuda a la diversidad de la población. En la selección se escogen aquellas soluciones que mayor fitness presentan.

\textit{SPEA2} hace uso de un archivo externo para almacenar soluciones no dominadas. Este archivo se actualiza en cada generación y mantiene un conjunto de soluciones que representan la mejor aproximación al frente de Pareto en ese momento.

Similar al \textit{NSGA-II}, este algoritmo escoge los mejores individuos de la combinación de padres y descendientes para la siguiente generación.~\cite{pymoo_spea2}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.5\textwidth]{figures/spea2.png}
  \caption{Cálculo del fitness en SPEA2. Fuente \cite{spea2_imagen}}
  \label{fig:spea2}
\end{figure}
\newpage
\subsubsection{Multi-Objective Evolutionary Algorithm based on Decomposition (MOEA/D)}
\label{ch:moead}

\textit{MOEA/D} hace uso de direcciones de referencia para dividir el problema multi-objetivo en problemas más pequeños de un solo objetivo. Cada dirección de referencia representa una combinación específica de los distintos objetivos. De manera ponderada, cada referencia se centra en la optimización de un objetivo particular. En el listado \ref{lst:direcciones} se muestra un ejemplo con 12 direcciones de referencia que puede ser utilizado en este proyecto, donde se busca una buena cobertura del espacio de búsqueda, que presenta 3 dimensiones (3 objetivos).

\begin{small}
\begin{lstlisting}[basicstyle=\ttfamily, caption=Direcciones de referencia.,label={lst:direcciones}]
    (1, 0, 0),          (0.67, 0.33, 0),    (0.33, 0.67, 0),
    (0, 1, 0),          (0.67, 0, 0.33),    (0.33, 0, 0.67)
    (0, 0.67, 0.33),    (0, 0.33, 0.67),    (0, 0, 1),
    (0.33, 0.33, 0.33), (0.67, 0.16, 0.16), (0.16, 0.67, 0.16)
\end{lstlisting}
\end{small}

Para generar estas direcciones existen distintos métodos, incluyendo \textit{''das-dennis''} e \textit{''incremental''}. El método \textit{''das-dennis''} es usado para distribuir uniformemente las direcciones, dividiendo el espacio en particiones equitativas. Mientras tanto, el método \textit{''incremental''} ajusta las direcciones de referencia gradualmente, permitiendo una adaptación más precisa a las áreas más prometedoras del espacio de búsqueda.

Para cada subproblema, se selecciona un número determinado de subproblemas más cercanos. Estos subproblemas forman el vecindario del primero, como se ilustra en la figura \ref{fig:moead}. Existe una probabilidad \( P_{cv} \) de que una solución se cruce con otra de su mismo vecindario. Compartir información entre vecinos ayuda a generar soluciones que cumplan cada uno de los subproblemas, por lo que son útiles para mejorar la calidad y la diversidad.~\cite{moead_pymoo}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.73\textwidth]{figures/moead.png}
  \caption{Vecindarios en MOEA/D. Fuente \cite{moead_imagen}}
  \label{fig:moead}
\end{figure}
\begin{comment}
  \subsection{Tabla comparativa entre SOP y MOP}

  \begin{table}[h!]
    \centering
    \renewcommand{\arraystretch}{1.5}
    \begin{tabularx}{\textwidth}{|l|X|X|}
    \hline
    \textbf{Campo} & \textbf{SOP (Single-Objective Optimization)} & \textbf{MOP (Multi-Objective Optimization)} \\
    \hline
    \textbf{Función objetivo} & Una única función objetivo & Varias funciones objetivo \\
    \hline
    \textbf{Meta} & Optimizar una solución & Balancear múltiples soluciones \\
    \hline
    \textbf{Solución} & Mejor solución única & Conjunto de Pareto \\
    \hline
    \textbf{Criterio} & Un criterio de éxito & Varios criterios de éxito \\
    \hline
    \textbf{Evaluación} & Valor numérico único & Valores numéricos múltiples \\
    \hline
    \textbf{Algoritmos comunes} & GA & NSGA-II,SPEA2,MOEA/D \\
    \hline
    \textbf{Búsqueda} & Explora grandes espacios de búsqueda & Usa criterios de Pareto para explorar el espacio de soluciones \\
    \hline
    \textbf{Clasificación} & - & Basada en dominancia \\
    \hline
    \textbf{Factibilidad} & Cumplir restricciones & Cumplir restricciones \\
    \hline
    \end{tabularx}
    \caption{Comparación entre SOP y MOP.}
    \label{table:sopvsmop}
  \end{table}

\end{comment}